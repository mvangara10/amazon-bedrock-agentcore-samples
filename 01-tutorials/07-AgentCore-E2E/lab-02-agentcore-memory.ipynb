{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 2: Personalize our agent by adding memory\n",
    "\n",
    "### Overview\n",
    "\n",
    "In Lab 1, you built a Customer Support Agent that worked well for a single user in a local session. However, real-world customer support needs to scale beyond a single user running in a local environment.\n",
    "\n",
    "When we run an **Agent in Production**, we'll need:\n",
    "- **Multi-User Support**: Handle thousands of customers simultaneously\n",
    "- **Persistent Storage**: Save conversations beyond session lifecycle\n",
    "- **Long-Term Learning**: Extract customer preferences and behavioral patterns\n",
    "- **Cross-Session Continuity**: Remember customers across different interactions\n",
    "\n",
    "**Workshop Progress:**\n",
    "- **Lab 1 (Done)**: Create Agent Prototype - Build a functional customer support agent\n",
    "- **Lab 2 (Current)**: Enhance with Memory - Add conversation context and personalization\n",
    "- **Lab 3**: Scale with Gateway & Identity - Share tools across agents securely\n",
    "- **Lab 4**: Deploy to Production - Use AgentCore Runtime with observability\n",
    "- **Lab 5**: Build User Interface - Create a customer-facing application\n",
    "\n",
    "\n",
    "In this lab, you'll add the missing persistence and learning layer that transforms your Goldfish-Agent (forgets the conversation in seconds) into an smart personalized Assistant.\n",
    "\n",
    "Memory is a critical component of intelligence. While Large Language Models (LLMs) have impressive capabilities, they lack persistent memory across conversations. [Amazon Bedrock AgentCore Memory](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/memory-getting-started.html) addresses this limitation by providing a managed service that enables AI agents to maintain context over time, remember important facts, and deliver consistent, personalized experiences.\n",
    "\n",
    "AgentCore Memory operates on two levels:\n",
    "- **Short-Term Memory**: Immediate conversation context and session-based information that provides continuity within a single interaction or closely related sessions.\n",
    "- **Long-Term Memory**: Persistent information extracted and stored across multiple conversations, including facts, preferences, and summaries that enable personalized experiences over time.\n",
    "\n",
    "### Architecture for Lab 2\n",
    "<div style=\"text-align:left\">\n",
    "    <img src=\"images/architecture_lab2_memory.png\" width=\"75%\"/>\n",
    "</div>\n",
    "\n",
    "*Multi-user agent with persistent short term and long term memory capabilities. *\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "* **AWS Account** with appropriate permissions\n",
    "* **Python 3.10+** installed locally\n",
    "* **AWS CLI configured** with credentials\n",
    "* **Anthropic Claude 3.7** enabled on [Amazon Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/model-access.html)\n",
    "* **Strands Agents** and other libraries installed in the next cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Libraries\n",
    "\n",
    "Let's import the libraries for AgentCore Memory. For it, we will use the [Amazon Bedrock AgentCore Python SDK](https://github.com/aws/bedrock-agentcore-sdk-python), a lightweight wrapper that helps you working with AgentCore capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Import agentCore Memory\n",
    "from bedrock_agentcore.memory import MemoryClient\n",
    "from bedrock_agentcore.memory.constants import StrategyType\n",
    "\n",
    "from strands.hooks import AfterInvocationEvent, HookProvider, HookRegistry, MessageAddedEvent\n",
    "\n",
    "import boto3\n",
    "from boto3.session import Session\n",
    "\n",
    "boto_session = Session()\n",
    "REGION = boto_session.region_name\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "from lab_helpers.utils import get_ssm_parameter, put_ssm_parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create Bedrock AgentCore Memory resources\n",
    "\n",
    "Amazon Bedrock AgentCore Memory provides multiple long-term memory strategies. We create a memory resource combining:\n",
    "\n",
    "- **USER_PREFERENCE**: Extracts customer preferences and behaviors\n",
    "- **SEMANTIC**: Stores factual information using vector embeddings\n",
    "\n",
    "AgentCore Memory uses namespaces to logically group long-term memory messages. Every time a new long-term memory is extracted using this memory strategy, it is saved under the namespace you set. We use the follwing namespaces using the `actorId` to group messaging of the same customer together:\n",
    "\n",
    "- `support/customer/{actorId}/preferences`: for the user preference memory strategy\n",
    "- `support/customer/{actorId}/semantic`: for the semantic memory strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_client = MemoryClient(region_name=REGION)\n",
    "memory_name = \"CustomerSupportMemory\"\n",
    "\n",
    "def create_or_get_memory_resource():\n",
    "    try:\n",
    "        memory_id = get_ssm_parameter(\"/app/customersupport/agentcore/memory_id\")\n",
    "        memory_client.gmcp_client.get_memory(memoryId=memory_id)\n",
    "        return memory_id\n",
    "    except:\n",
    "        try:\n",
    "            strategies = [\n",
    "                {\n",
    "                    StrategyType.USER_PREFERENCE.value: {\n",
    "                        \"name\": \"CustomerPreferences\",\n",
    "                        \"description\": \"Captures customer preferences and behavior\",\n",
    "                        \"namespaces\": [\"support/customer/{actorId}/preferences\"],\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    StrategyType.SEMANTIC.value: {\n",
    "                        \"name\": \"CustomerSupportSemantic\",\n",
    "                        \"description\": \"Stores facts from conversations\",\n",
    "                        \"namespaces\": [\"support/customer/{actorId}/semantic\"],\n",
    "                    }\n",
    "                },\n",
    "            ]\n",
    "            print(\"Creating AgentCore Memory resources. This can a couple of minutes..\")\n",
    "            # *** AGENTCORE MEMORY USAGE *** - Create memory resource with semantic strategy\n",
    "            response = memory_client.create_memory_and_wait(\n",
    "                name=memory_name,\n",
    "                description=\"Customer support agent memory\",\n",
    "                strategies=strategies,\n",
    "                event_expiry_days=90,          # Memories expire after 90 days\n",
    "            )\n",
    "            memory_id = response[\"id\"]\n",
    "            try:\n",
    "                put_ssm_parameter(\"/app/customersupport/agentcore/memory_id\", memory_id)\n",
    "            except:\n",
    "                raise\n",
    "            return memory_id\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_id = create_or_get_memory_resource()\n",
    "print(\"AgentCore Memory created successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Seed previous customer \n",
    "\n",
    "The `create_event` action stores agent interactions into short-term memory instantly. Each saved interaction can include user messages, assistant responses, and tool actions. The process is synchronous, ensuring no conversation data is lost.\n",
    "\n",
    "Short-term memory messages are then asynchronously processed according to the chosen long-term memory strategy.\n",
    "\n",
    "Let's load some previously customer interactions providing the customer id as `actor_id` and a `session_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List existing memory resources\n",
    "for memory in memory_client.list_memories():\n",
    "    print(f\"Memory Arn: {memory.get('arn')}\")\n",
    "    print(f\"Memory ID: {memory.get('id')}\")\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "\n",
    "# Seed with previous customer interactions\n",
    "CUSTOMER_ID = \"customer_001\"\n",
    "\n",
    "previous_interactions = [\n",
    "    (\"I'm having issues with my MacBook Pro overheating during video editing.\",\"USER\"),\n",
    "    (\"I can help with that thermal issue. For video editing workloads, let's check your Activity Monitor and adjust performance settings. Your MacBook Pro order #MB-78432 is still under warranty.\", \"ASSISTANT\"),\n",
    "    (\"What's the return policy on gaming headphones? I need low latency for competitive FPS games\", \"USER\"),\n",
    "    (\"For gaming headphones, you have 30 days to return. Since you're into competitive FPS, I'd recommend checking the audio latency specs - most gaming models have <40ms latency.\", \"ASSISTANT\"),\n",
    "    (\"I need a laptop under $1200 for programming. Prefer 16GB RAM minimum and good Linux compatibility. I like ThinkPad models.\", \"USER\"),\n",
    "    (\"Perfect! For development work, I'd suggest looking at our ThinkPad E series or Dell XPS models. Both have excellent Linux support and 16GB RAM options within your budget.\", \"ASSISTANT\"),\n",
    "]\n",
    "\n",
    "# Save previous interactions\n",
    "try:\n",
    "    memory_client.create_event(\n",
    "        memory_id=memory_id,\n",
    "        actor_id=CUSTOMER_ID,\n",
    "        session_id=\"previous_session\",\n",
    "        messages=previous_interactions\n",
    "    )\n",
    "    print(\"✅ Seeded customer history\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Error seeding history: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you create an event via `create_event`, messages are sent to short-term memory and further asynchronously sent to [Long Term memory](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/long-term-memory.html).\n",
    "It takes about 30 seconds to propogate the information to Long-Term Memory.\n",
    "\n",
    "### Visualize preferences memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "time.sleep(20) # To give some time for memory propogation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memories = memory_client.retrieve_memories(\n",
    "    memory_id=memory_id,\n",
    "    namespace=f\"support/customer/{CUSTOMER_ID}/preferences\",\n",
    "    query=\"can you summarize the support issue\"\n",
    ")\n",
    "\n",
    "for i, memory in enumerate(memories, 1):\n",
    "    if isinstance(memory, dict):\n",
    "        content = memory.get('content', {})\n",
    "        if isinstance(content, dict):\n",
    "            text = content.get('text', '')\n",
    "            print(f\"  {i}. {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Let's look at Semantic memory"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memories = memory_client.retrieve_memories(\n",
    "    memory_id=memory_id,\n",
    "    namespace=f\"support/customer/{CUSTOMER_ID}/semantic\",\n",
    "    query=\"can you summarize the support issue\"\n",
    ")\n",
    "\n",
    "for i, memory in enumerate(memories, 1):\n",
    "    if isinstance(memory, dict):\n",
    "        content = memory.get('content', {})\n",
    "        if isinstance(content, dict):\n",
    "            text = content.get('text', '')\n",
    "            print(f\"  {i}. {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Implement Strands Hooks to save and retrieve agent interactions\n",
    "\n",
    "Strands Agents provides a powerful hook system that enables components to react to or modify agent behavior through strongly-typed event callbacks. We'll use two key hook events:\n",
    "\n",
    "- **MessageAddedEvent**: Triggered when messages are added to the conversation, allowing us to retrieve and inject customer context\n",
    "- **AfterInvocationEvent**: Fired after agent responses, enabling automatic storage of interactions to memory\n",
    "\n",
    "The hook system ensures memory operations happen automatically without manual intervention, creating a seamless experience where customer context is preserved across conversations.\n",
    "\n",
    "To create the hooks we will extend the `HookProvider` class:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerSupportMemoryHooks(HookProvider):\n",
    "    \"\"\"Memory hooks for customer support agent\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, memory_id: str, client: MemoryClient, actor_id: str, session_id: str\n",
    "    ):\n",
    "        self.memory_id = memory_id\n",
    "        self.client = client\n",
    "        self.actor_id = actor_id\n",
    "        self.session_id = session_id\n",
    "        self.namespaces = {\n",
    "            i[\"type\"]: i[\"namespaces\"][0]\n",
    "            for i in self.client.get_memory_strategies(self.memory_id)\n",
    "        }\n",
    "\n",
    "    def retrieve_customer_context(self, event: MessageAddedEvent):\n",
    "        \"\"\"Retrieve customer context before processing support query\"\"\"\n",
    "        messages = event.agent.messages\n",
    "        if (\n",
    "            messages[-1][\"role\"] == \"user\"\n",
    "            and \"toolResult\" not in messages[-1][\"content\"][0]\n",
    "        ):\n",
    "            user_query = messages[-1][\"content\"][0][\"text\"]\n",
    "\n",
    "            try:\n",
    "                all_context = []\n",
    "\n",
    "                for context_type, namespace in self.namespaces.items():\n",
    "                    # *** AGENTCORE MEMORY USAGE *** - Retrieve customer context from each namespace\n",
    "                    memories = self.client.retrieve_memories(\n",
    "                        memory_id=self.memory_id,\n",
    "                        namespace=namespace.format(actorId=self.actor_id),\n",
    "                        query=user_query,\n",
    "                        top_k=3,\n",
    "                    )\n",
    "                    # Post-processing: Format memories into context strings\n",
    "                    for memory in memories:\n",
    "                        if isinstance(memory, dict):\n",
    "                            content = memory.get(\"content\", {})\n",
    "                            if isinstance(content, dict):\n",
    "                                text = content.get(\"text\", \"\").strip()\n",
    "                                if text:\n",
    "                                    all_context.append(\n",
    "                                        f\"[{context_type.upper()}] {text}\"\n",
    "                                    )\n",
    "\n",
    "                # Inject customer context into the query\n",
    "                if all_context:\n",
    "                    context_text = \"\\n\".join(all_context)\n",
    "                    original_text = messages[-1][\"content\"][0][\"text\"]\n",
    "                    messages[-1][\"content\"][0][\n",
    "                        \"text\"\n",
    "                    ] = f\"Customer Context:\\n{context_text}\\n\\n{original_text}\"\n",
    "                    logger.info(f\"Retrieved {len(all_context)} customer context items\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to retrieve customer context: {e}\")\n",
    "\n",
    "    def save_support_interaction(self, event: AfterInvocationEvent):\n",
    "        \"\"\"Save customer support interaction after agent response\"\"\"\n",
    "        try:\n",
    "            messages = event.agent.messages\n",
    "            if len(messages) >= 2 and messages[-1][\"role\"] == \"assistant\":\n",
    "                # Get last customer query and agent response\n",
    "                customer_query = None\n",
    "                agent_response = None\n",
    "\n",
    "                for msg in reversed(messages):\n",
    "                    if msg[\"role\"] == \"assistant\" and not agent_response:\n",
    "                        agent_response = msg[\"content\"][0][\"text\"]\n",
    "                    elif (\n",
    "                        msg[\"role\"] == \"user\"\n",
    "                        and not customer_query\n",
    "                        and \"toolResult\" not in msg[\"content\"][0]\n",
    "                    ):\n",
    "                        customer_query = msg[\"content\"][0][\"text\"]\n",
    "                        break\n",
    "\n",
    "                if customer_query and agent_response:\n",
    "                    # *** AGENTCORE MEMORY USAGE *** - Save the support interaction\n",
    "                    self.client.create_event(\n",
    "                        memory_id=self.memory_id,\n",
    "                        actor_id=self.actor_id,\n",
    "                        session_id=self.session_id,\n",
    "                        messages=[\n",
    "                            (customer_query, \"USER\"),\n",
    "                            (agent_response, \"ASSISTANT\"),\n",
    "                        ],\n",
    "                    )\n",
    "                    logger.info(\"Saved support interaction to memory\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to save support interaction: {e}\")\n",
    "\n",
    "    def register_hooks(self, registry: HookRegistry) -> None:\n",
    "        \"\"\"Register customer support memory hooks\"\"\"\n",
    "        registry.add_callback(MessageAddedEvent, self.retrieve_customer_context)\n",
    "        registry.add_callback(AfterInvocationEvent, self.save_support_interaction)\n",
    "        logger.info(\"Customer support memory hooks registered\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create a Customer Support Agent with memory\n",
    "\n",
    "Next, we will implement the Customer Support Agent just as we did in Lab 1, but this time we instantiate the class `CustomerSupportMemoryHooks` and we pass the memory hook to the agent contructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from strands import Agent\n",
    "from strands.models import BedrockModel\n",
    "\n",
    "from lab_helpers.lab1_strands_agent import (\n",
    "    SYSTEM_PROMPT,\n",
    "    get_return_policy, web_search,\n",
    "    get_product_info, MODEL_ID\n",
    ")\n",
    "\n",
    "SESSION_ID = str(uuid.uuid4())\n",
    "memory_hooks = CustomerSupportMemoryHooks(memory_id, memory_client, CUSTOMER_ID, SESSION_ID)\n",
    "\n",
    "\n",
    "# Initialize the Bedrock model (Anthropic Claude 3.7 Sonnet)\n",
    "model = BedrockModel(\n",
    "    model_id=MODEL_ID,\n",
    "    region_name=REGION\n",
    ")\n",
    "\n",
    "# Create the customer support agent with all 5 tools\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    hooks=[memory_hooks], # Pass Memory Hooks\n",
    "    tools=[\n",
    "        get_product_info,      # Tool 1: Simple product information lookup\n",
    "        get_return_policy,      # Tool 2: Simple return policy lookup\n",
    "        web_search,\n",
    "    ],\n",
    "    system_prompt=SYSTEM_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Test Memory Hooks\n",
    "\n",
    "Now let's test how the sophisticated MemoryHook system works automatically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response1 = agent(\"Which headphones would you recommend?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response1 = agent(\"What is my preferred Laptop?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! 🎉\n",
    "\n",
    "You have successfully completed **Lab 2: Add memory to the Customer Support Agent**!\n",
    "\n",
    "### What You Accomplished:\n",
    "\n",
    "- Created a serverless managed memory with Amazon Bedrock AgentCore Memory\n",
    "- Implemented long-term memory to store User-Preferences and Semantic (Factual) information.\n",
    "- Integrated AgentCore Memory with the customer support Agent using the hook mechanism provided by Strands Agents\n",
    "\n",
    "##### Next Up [Lab 3 - Scaling with Gateway and Identity  →](lab-03-agentcore-gateway.ipynb)\n",
    "\n",
    "## Resources\n",
    "- [Amazon Bedrock Agent Core Memory](https://docs.aws.amazon.com/bedrock-agentcore/latest/devguide/memory.html)\n",
    "- [Strands Agents Hooks Documentation](https://strandsagents.com/latest/documentation/docs/user-guide/concepts/agents/hooks/?h=hooks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
